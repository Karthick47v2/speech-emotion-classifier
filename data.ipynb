{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthick47v2/speech-emotion-classifier/blob/main/feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UFPW2Dnget7"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle datasets download uwrfkaggler/ravdess-emotional-speech-audio\n",
        "! kaggle datasets download ejlok1/surrey-audiovisual-expressed-emotion-savee\n",
        "! kaggle datasets download ejlok1/toronto-emotional-speech-set-tess\n",
        "\n",
        "! unzip ravdess-emotional-speech-audio\n",
        "! unzip surrey-audiovisual-expressed-emotion-savee\n",
        "! unzip toronto-emotional-speech-set-tess\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qwthWHlg58y"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYZxgrn9g_Fo"
      },
      "outputs": [],
      "source": [
        "# Mapping\n",
        "\n",
        "# 1 - neutral\n",
        "# 2 - calm ##\n",
        "# 3 - happy\n",
        "# 4 - sad\n",
        "# 5 - angry\n",
        "# 6 - fear\n",
        "# 7 - disgust\n",
        "# 8 - surprise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p_ru43lhg7O"
      },
      "outputs": [],
      "source": [
        "# RAVDESS\n",
        "r_path_list = glob.glob('/content/Actor_*/**')\n",
        "r_emotion_list = [int((x.split('.')[0]).split('-')[2]) for x in r_path_list]\n",
        "r_df = pd.DataFrame({'path': r_path_list, 'emotion': r_emotion_list})\n",
        "\n",
        "# SAVEES\n",
        "s_path_list = glob.glob('/content/ALL/**')\n",
        "s_emotion_list = [(list((x.split('.')[0]).split('_')[1])[0]) + (list((x.split('.')[0]).split('_')[1])\n",
        "                                                                [1] if list((x.split('.')[0]).split('_')[1])[0] == 's' else '0') for x in s_path_list]\n",
        "s_df = pd.DataFrame({'path': s_path_list, 'emotion': s_emotion_list})\n",
        "\n",
        "# TESS\n",
        "t_path_list = glob.glob(\n",
        "    '/content/TESS Toronto emotional speech set data/**/**')\n",
        "t_emotion_list = [((x.split('.')[0]).split('/')[-1].split('_')[-1])\n",
        "                  for x in t_path_list]\n",
        "t_df = pd.DataFrame({'path': t_path_list, 'emotion': t_emotion_list})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drop 'Calm' as we are not interested in it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn5J6Do2lVrc"
      },
      "outputs": [],
      "source": [
        "s_df['emotion'] = s_df['emotion'].replace(\n",
        "    ['a0', 'd0', 'f0', 'h0', 'n0', 'sa', 'su'], [5, 7, 6, 3, 1, 4, 8])\n",
        "t_df['emotion'] = t_df['emotion'].replace(\n",
        "    ['angry', 'disgust', 'fear', 'happy', 'neutral', 'ps', 'sad'], [5, 7, 6, 3, 1, 8, 4])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6BKtNNTmJbo"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([r_df, s_df, t_df], ignore_index=True)\n",
        "df = df[df['emotion'] != 2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSh7YMYJptrU"
      },
      "outputs": [],
      "source": [
        "df['emotion'].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As there are no large different b/w counts we don't need to care about class weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPXu7y90h5MD"
      },
      "outputs": [],
      "source": [
        "wav_len = []\n",
        "\n",
        "for path in df['path']:\n",
        "    y, sr = librosa.load(path, sr=None, mono=True)\n",
        "\n",
        "    wav_len.append(y.shape[0] / sr)\n",
        "\n",
        "df['length'] = wav_len\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgcx4o0TmepV"
      },
      "outputs": [],
      "source": [
        "df.groupby(['emotion'])['length'].mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqjKIu_qDScu"
      },
      "outputs": [],
      "source": [
        "hist = df.hist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rc0poPXxDao"
      },
      "source": [
        "TAKE 4s (4 \\* 22050 = 88200)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXmpcn_BFBel"
      },
      "outputs": [],
      "source": [
        "y, sr = librosa.load(df['path'][0], mono=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "wave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppfzGJIGB9HR"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.waveshow(y, sr=sr)\n",
        "plt.title('waveform')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "trim silenced time in leading and trailing parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbTKHCirGIKu"
      },
      "outputs": [],
      "source": [
        "trimmed_y, idx = librosa.effects.trim(y, top_db=50)\n",
        "librosa.display.waveshow(trimmed_y, sr=sr)\n",
        "plt.title('trimmed waveform')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "STFT (Short-Time Fourier Transform) spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxaDS4xEGjJJ"
      },
      "outputs": [],
      "source": [
        "n_fft = 2048\n",
        "hop_length = 512\n",
        "\n",
        "# normalize\n",
        "normalized_y = librosa.util.normalize(trimmed_y)\n",
        "# short-term fourier transform\n",
        "stft = librosa.core.stft(normalized_y, n_fft=n_fft, hop_length=hop_length)\n",
        "# log scale\n",
        "db = librosa.amplitude_to_db(abs(stft))\n",
        "\n",
        "librosa.display.specshow(db, x_axis='time', y_axis='log')\n",
        "plt.title('STFT')\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MFCC (Mel Frequency Cepstral Coefficient) Spectrogram (FEATURE #1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfDH1qWoIwTO"
      },
      "outputs": [],
      "source": [
        "# mfcc\n",
        "mfcc = librosa.feature.mfcc(normalized_y, sr, n_mfcc=13)\n",
        "\n",
        "librosa.display.specshow(mfcc, x_axis='time', y_axis='mel')\n",
        "plt.title('MFCC')\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Log-MEL Spectrogram (FEATURE #2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKJmRHEYNONg"
      },
      "outputs": [],
      "source": [
        "# mel scaled spectogram\n",
        "mel = librosa.feature.melspectrogram(S=stft, n_mels=128)\n",
        "\n",
        "mel_db = librosa.amplitude_to_db(abs(mel))\n",
        "# mel_db = librosa.util.normalize(mel_db)\n",
        "\n",
        "librosa.display.specshow(mel_db, x_axis='time', y_axis='mel')\n",
        "plt.title('Mel-Scaled')\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2JSZ6-bcB26"
      },
      "outputs": [],
      "source": [
        "def load_wav(path, stop):\n",
        "    # 22.05 kHz, 16 bit\n",
        "    y, sr = librosa.load(path, mono=True)\n",
        "    trimmed_y, idx = librosa.effects.trim(y, top_db=50)\n",
        "    normalized_y = librosa.util.normalize(trimmed_y)\n",
        "    y_chunks = [normalized_y[i:(i+stop)]\n",
        "                for i in range(0, len(normalized_y), stop)]\n",
        "    return y_chunks, sr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaIliM_6SpbS"
      },
      "outputs": [],
      "source": [
        "def extract_mfcc(y, sr, n_mfcc, n_fft, hop_length):\n",
        "    mfcc = librosa.feature.mfcc(\n",
        "        y=y, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "    normalized_mfcc = librosa.util.normalize(mfcc)\n",
        "\n",
        "    return normalized_mfcc\n",
        "\n",
        "\n",
        "def extract_mel(y, n_mel, n_fft, hop_length):\n",
        "    stft = librosa.core.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "    mel = librosa.feature.melspectrogram(S=stft, n_mels=n_mel)\n",
        "    mel_db = librosa.amplitude_to_db(abs(mel))\n",
        "    normalized_mel = librosa.util.normalize(mel_db)\n",
        "\n",
        "    return normalized_mel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j6QEDIFOxHt"
      },
      "outputs": [],
      "source": [
        "# augmentation - noise\n",
        "\n",
        "def add_noise(y, s_noise, e_noise):\n",
        "    noise = random.uniform(s_noise, e_noise)\n",
        "    noised_y = y + np.random.rand(len(y)) * noise\n",
        "\n",
        "    return noised_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7FdzdSPU5TW"
      },
      "outputs": [],
      "source": [
        "def add_padding(x, padding):\n",
        "    padded_x = []\n",
        "\n",
        "    for i in x:\n",
        "        sh = len(i[0])\n",
        "\n",
        "        if padding > 0 & sh < padding:\n",
        "            x = padding - sh\n",
        "            l_pad = x // 2\n",
        "            r_pad = x - l_pad\n",
        "            i = np.pad(i, pad_width=((0, 0), (l_pad, r_pad)), mode='constant')\n",
        "\n",
        "        padded_x.append(i)\n",
        "\n",
        "    return padded_x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- n_fft = 2048, hop_length = 512 gave high accuracy with relatively small model..\n",
        "- we divide audio into 4s chunks and process (we will get 2 data from 4 < x <= 8 audio clip)\n",
        "- max_frame for this config is, 173 frames. Which needs to be noted as we need to preprocess our data for prediction\n",
        "- 13 MFCC coefficients and 128 filter banks for Log-Mel taken to this study as it would be more than enough.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GVBxerZNW9A"
      },
      "outputs": [],
      "source": [
        "mfcc = []\n",
        "mel = []\n",
        "label = []\n",
        "max_frame = 0\n",
        "\n",
        "n_fft = 2048\n",
        "hop_length = 512\n",
        "\n",
        "add_aug = True\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    y_chunks, sr = load_wav(row['path'], 88200)\n",
        "\n",
        "    for y in y_chunks:\n",
        "\n",
        "        if len(y) >= n_fft:\n",
        "\n",
        "            ex_mfcc = extract_mfcc(y, sr, 13, n_fft, hop_length)\n",
        "            ex_mel = extract_mel(y, 128, n_fft, hop_length)\n",
        "\n",
        "            mfcc.append(ex_mfcc)\n",
        "            mel.append(ex_mel)\n",
        "            label.append(row['emotion'])\n",
        "\n",
        "            if add_aug:\n",
        "                noised_y = add_noise(y, 0.005, 0.02)\n",
        "\n",
        "                aug_mfcc = extract_mfcc(noised_y, sr, 13, n_fft, hop_length)\n",
        "                aug_mel = extract_mel(noised_y, 128, n_fft, hop_length)\n",
        "\n",
        "                mfcc.append(aug_mfcc)\n",
        "                mel.append(aug_mel)\n",
        "                label.append(row['emotion'])\n",
        "\n",
        "            if max_frame < ex_mfcc.shape[1]:\n",
        "                max_frame = ex_mfcc.shape[1]\n",
        "\n",
        "padded_mfcc = add_padding(mfcc, max_frame)\n",
        "padded_mel = add_padding(mel, max_frame)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3aQsv7n59iC",
        "outputId": "574de37c-4523-459a-c6d3-40bd1b2c0635"
      },
      "outputs": [],
      "source": [
        "np.unique(label, return_counts=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "YJRtbMMefbk0",
        "outputId": "8c7cf8fd-4ef4-430d-ca9c-e7f5c13b43ac"
      },
      "outputs": [],
      "source": [
        "librosa.display.specshow(padded_mel[1000], x_axis='time', y_axis='mel')\n",
        "plt.title('Mel-Scaled')\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "CB5hnvfBg4CU",
        "outputId": "5e5c6b39-3993-421c-fd7a-5603af099b2a"
      },
      "outputs": [],
      "source": [
        "librosa.display.specshow(padded_mfcc[0], x_axis='time', y_axis='mel')\n",
        "plt.title('Mel-Scaled')\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up8uxphabQJN"
      },
      "outputs": [],
      "source": [
        "X_mfcc = np.array(padded_mfcc)\n",
        "X_mel = np.array(padded_mel)\n",
        "y = np.array(label)\n",
        "\n",
        "np.save('X_mfcc_2048', X_mfcc)\n",
        "np.save('X_mel_2048', X_mel)\n",
        "np.save('y_2048', y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAe476zzezeO",
        "outputId": "27064d43-be3f-4844-e103-b5e2514b07cb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njVxNbTW50uY"
      },
      "outputs": [],
      "source": [
        "! mv X_mel_2048.npy X_mfcc_2048.npy y_2048.npy drive/MyDrive/SER\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNUuP998uC06jph65QMVNx6",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
