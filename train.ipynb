{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthick47v2/speech-emotion-classifier/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bNZZtnXnrJkl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and split data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MQcVZ1Njq7rs"
      },
      "outputs": [],
      "source": [
        "X_mfcc = np.load('drive/MyDrive/SER/X_mfcc_2048.npy')\n",
        "X_mel = np.load('drive/MyDrive/SER/X_mel_2048.npy')\n",
        "y = np.load('drive/MyDrive/SER/y_2048.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jkylGiBwugOK"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "y_encoded = to_categorical(le.fit_transform(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nzMYI8Morele"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    X_mel, y_encoded, random_state=42, test_size=0.1)\n",
        "x_test, x_T_test, y_test, y_T_test = train_test_split(\n",
        "    x_test, y_test, random_state=42, test_size=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgsAmw6_svd0"
      },
      "outputs": [],
      "source": [
        "n_rows = x_train.shape[1]\n",
        "n_cols = x_train.shape[2]\n",
        "n_channels = 1\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], n_rows, n_cols, n_channels)\n",
        "x_test = x_test.reshape(x_test.shape[0], n_rows, n_cols, n_channels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model - Log-MEL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYMy1hQUvvc2"
      },
      "outputs": [],
      "source": [
        "# # MEL - 300 EPOCHS\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=16, kernel_size=(5, 5), kernel_initializer=\"he_normal\",\n",
        "          input_shape=(n_rows, n_cols, n_channels), activation='relu'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(6, 6)))\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3, 3),\n",
        "          activation='relu', kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(6, 6)))\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=48, kernel_size=(3, 3),\n",
        "          activation='relu', kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(keras.layers.Dropout(0.7))\n",
        "\n",
        "model.add(keras.layers.GlobalAveragePooling2D())\n",
        "model.add(keras.layers.Dense(units=7, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=[\n",
        "              'accuracy'], optimizer=keras.optimizers.Adam(learning_rate=2e-4))  # 2\n",
        "\n",
        "# model.summary()\n",
        "n_epochs = 300\n",
        "batch_size = 32\n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath='mel-model',\n",
        "                                             monitor='val_loss',\n",
        "                                             mode='min',\n",
        "                                             save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=n_epochs,\n",
        "                    validation_data=(x_test, y_test), callbacks=[checkpoint], verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, label='Training acc')\n",
        "plt.plot(epochs, val_acc, label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, label='Training loss')\n",
        "plt.plot(epochs, val_loss, label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model - MFCC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAtXz3CEgiX8"
      },
      "outputs": [],
      "source": [
        "# MFCC - 300 epochs\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=16, kernel_size=(3, 3), kernel_initializer=\"he_normal\",\n",
        "          input_shape=(n_rows, n_cols, n_channels), activation='relu'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3, 3),\n",
        "          activation='relu', kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=48, kernel_size=(3, 3),\n",
        "          activation='relu', kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.Dropout(0.7))\n",
        "\n",
        "model.add(keras.layers.GlobalAveragePooling2D())\n",
        "model.add(keras.layers.Dense(units=7, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=[\n",
        "              'accuracy'], optimizer=keras.optimizers.Adam(learning_rate=4e-4))  # 2\n",
        "\n",
        "# model.summary()\n",
        "n_epochs = 300\n",
        "batch_size = 32\n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath='mfcc-model',\n",
        "                                             monitor='val_loss',\n",
        "                                             mode='min',\n",
        "                                             save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=n_epochs,\n",
        "                    validation_data=(x_test, y_test), callbacks=[checkpoint], verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLj3yF3WbIto"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, label='Training acc')\n",
        "plt.plot(epochs, val_acc, label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, label='Training loss')\n",
        "plt.plot(epochs, val_loss, label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTYxIflgpunz"
      },
      "outputs": [],
      "source": [
        "! unzip mel_2048.zip\n",
        "! unzip mfcc_2048.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Log-MEL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "q8wDwrCIjnOz"
      },
      "outputs": [],
      "source": [
        "# test\n",
        "mel_model = keras.models.load_model('mel_2048')\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    X_mel, y_encoded, random_state=42, test_size=0.1)\n",
        "x_test, x_MEL_test, y_test, y_MEL_test = train_test_split(\n",
        "    x_test, y_test, random_state=42, test_size=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "yvJ01sXh0M0f",
        "outputId": "a5f5d979-7b4b-4408-b181-013d8b387243"
      },
      "outputs": [],
      "source": [
        "y_preds = mel_model.predict(x_MEL_test)\n",
        "y_hat = np.argmax(y_preds, axis=1)\n",
        "y_true = np.argmax(y_MEL_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_hat)\n",
        "\n",
        "sum = 0\n",
        "\n",
        "for i in range(cm.shape[0]):\n",
        "    sum += cm[i, i]\n",
        "\n",
        "print(len(y_preds))\n",
        "print(sum / len(y_preds))\n",
        "print(f1_score(y_true, y_hat, average='weighted'))\n",
        "sns.heatmap(cm, annot=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MFCC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "l_qjGDKErUrC"
      },
      "outputs": [],
      "source": [
        "mfcc_model = keras.models.load_model('mfcc_2048')\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    X_mfcc, y_encoded, random_state=42, test_size=0.1)\n",
        "x_test, x_MFCC_test, y_test, y_MFCC_test = train_test_split(\n",
        "    x_test, y_test, random_state=42, test_size=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "PWoms0pMruWn",
        "outputId": "95670ffe-41e6-4811-b217-fd4bd94cdb4b"
      },
      "outputs": [],
      "source": [
        "y_preds = mfcc_model.predict(x_MFCC_test)\n",
        "y_hat = np.argmax(y_preds, axis=1)\n",
        "y_true = np.argmax(y_MFCC_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_hat)\n",
        "\n",
        "sum = 0\n",
        "\n",
        "for i in range(cm.shape[0]):\n",
        "    sum += cm[i, i]\n",
        "\n",
        "print(len(y_preds))\n",
        "print(sum / len(y_preds))\n",
        "print(f1_score(y_true, y_hat, average='weighted'))\n",
        "sns.heatmap(cm, annot=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ensembled model (Bagging)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "oJMblJ5Xt_4e",
        "outputId": "b72a9eaa-7260-4843-bf81-33c1b53a23ab"
      },
      "outputs": [],
      "source": [
        "y1_preds = mfcc_model.predict(x_MFCC_test)\n",
        "y2_preds = mel_model.predict(x_MEL_test)\n",
        "y_preds = y1_preds * 0.7 + y2_preds * 0.3\n",
        "y_hat = np.argmax(y_preds, axis=1)\n",
        "y_true = np.argmax(y_T_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_hat)\n",
        "\n",
        "sum = 0\n",
        "\n",
        "for i in range(cm.shape[0]):\n",
        "    sum += cm[i, i]\n",
        "\n",
        "print(len(y_preds))\n",
        "print(sum / len(y_preds))\n",
        "print(f1_score(y_true, y_hat, average='weighted'))\n",
        "sns.heatmap(cm, annot=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
